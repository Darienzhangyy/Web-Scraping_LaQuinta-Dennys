---
title: "hw2"
output: pdf_document
---



**get_lq.R**

This document implements procedures to download websites of LaQuinta hotels that primarity operates in the United States and store those links into directory "data/lq/". We extract websites of those hotels by implementing a function named 'scrape_list' such that it has following functionality: (1) matching US state names from csv file to US state abbreviations on website to identify American hotels; (2) extracting country/state abbreviations and replace NA with "NA""; (3) extracting the indexes from `rows` corresponding to the first entry after the US label and before the Mexico label; (4) extracting the indexes from `rows` corresponding to the state abbreviations; (5) extracting the indexes from `rows` immediately following the state abbreviations and corresponding to all American hotels; (6) extracting the links from the nodes indexed by `state_rows`and return those links. Finally we implement the 'html_download' function to download those links that are extracted by 'Scrape_list' and store them into directory "data/lq/". \newline

  
\quad\newline

**parse_lq.R**

This documents primary parses LaQuinta's hotel information of "name", "address", "phone", "fax", "latitude", "longtitude", "amenities", and "details" and store them as lq.Rdata in the "data/" directory. We first create a function named 'scrape_hotel' that it takes input as 'page' <full html file for a particular La Quinta hotel's webpage>, and returns output which is a list of 8 character vectors as above. After obtaining  the relative information, we then (1) check hotel names and addresses by visual inspection; (2) check hotel phone numbers by adherence to "1-xxx-xxx-xxxx" pattern and correct as needed; (3) replace " " with "-" corrects all flaws; (4) check hotel fax numbers by adherence to "1-xxx-xxx-xxxx" pattern and correct as needed; (5) replace " " with "-" corrects most - but not all - flaws; (6) insert "-" in the last seven digits corrects one more flaw; (7) trim leading zeroes corrects one more flaw; (8) convert three remaining flaws involve missing data to NAs;(9) check hotel names, addresses, hotel amenities, details correct and consistent as needed;(10) define and call a function to standardize hotel details and store those information into 'data/' directory. 

The constructed data frame has the following column names:
   
   (1) name, the name of the hotel;

   (2) address, the address of the hotel;

   (3) phone, the phone number of the hotel;

   (4) fax, the fax number of the hotel;

   (5) latitude, the latitude of the hotel location;

   (6) longitude, the longitude of the hotel location;

   (7) amenities, the features of the hotel and the room;

   (8) details, the hotel details (# rooms, floors, etc.). \newline


\quad\newline

**get_dannys.R**

This document implements steps to download xml data from the Where2GetIt API and store them into 'data/dennys/' directory. We first implement a function named query_api that it takes input as 'coordinate' <a data frame row containing a longitude, a latitude, and a search radius, key (default=api_key) <a valid API key allowing data scraping>, and limit (default=1000) <an upper bound for the number of search results returned> It returns an output of XML file containing the results of the API query is downloaded to disk. Finally we run query_api on the rows of the 'dennys_coords.csv' data frame to download XML files containing Dennys locations.\newline


\quad\newline

**parse_dannys.R**

This documents parse denny's stores data and stores corresponding information as 'dennys.Rdata' in the 'data/' directory. We implement the procedures by (1) letting R read in xml file to a list;(2) creating a logical vector for subsetting the unique store ID numbers;(3) extracting the results nodes for the unique Dennys locations;(4) creating a function named scrape_tag() such that it takes inputs 'tag' <a particular xml tag whose value is to be extracted>, and 'result'<a particular result node>. The function then returns an output that contains the value of the xml tag. We also create a function named scrape_dennys() that it takes input 'result' <a particular result node> and returns output as a character vector with five elements:
            
            (1) clientkey, a unique store ID;
            
            (2) address, the address of the Dennys location;
            
            (3) phone, the phone number of the Dennys location;
            
            (4) latitude, the latitude of the Dennys location;
      
            (5) longitude, the longitude of the Dennys location.
           
We then extract the relevant information from the search results into a data frame, subset the data frame to include only US locations (those with a state abbreviation and ZIP code) and store them into 'data/' directory.




